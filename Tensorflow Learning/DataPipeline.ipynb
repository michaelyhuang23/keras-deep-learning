{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import numpy as np\n",
    "# keras has several built in datasets for learning:\n",
    "# refer to https://keras.io/api/datasets/\n",
    "# each dataset has its own keyword arguments when we load it in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_train_data,imdb_train_labels),(imdb_test_data,imdb_test_labels) = datasets.imdb.load_data(num_words=1000,skip_top=50,maxlen=100)\n",
    "# num_words: only load top 1000 frequent words\n",
    "# skip_top: skip the top 50 most frequent words\n",
    "# maxlen: each sample has a list of words, this sets its maxlen\n",
    "# ...\n",
    "(mnist_train_data, mnist_train_labels),(mnist_test_data, mnist_test_labels) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(train_data, train_labels, batch_size=1):\n",
    "    while True:\n",
    "        for step in range(train_labels.shape[0]//batch_size):\n",
    "            yield (train_data[step*batch_size:(step+1)*batch_size],train_labels[step*batch_size:(step+1)*batch_size])\n",
    "        permutes = np.random.permutation(range(train_labels.shape[0]))\n",
    "        train_data = train_data[permutes]\n",
    "        train_labels = train_labels[permutes]\n",
    "\n",
    "def val_generator(test_data, test_labels, batch_size=1):\n",
    "    for step in range(test_labels.shape[0]//batch_size):\n",
    "            yield (test_data[step*batch_size:(step+1)*batch_size],test_labels[step*batch_size:(step+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = data_generator(mnist_train_data,mnist_train_labels,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Flatten(),Dense(64, activation='relu'),Dense(10, activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = val_generator(mnist_test_data,mnist_test_labels,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 1s 974us/step - loss: 0.1652 - sparse_categorical_accuracy: 0.9547 - val_loss: 0.2831 - val_sparse_categorical_accuracy: 0.9302\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 1s 940us/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9543 - val_loss: 0.3145 - val_sparse_categorical_accuracy: 0.9146\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 1s 884us/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.9292\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 1s 897us/step - loss: 0.1516 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.2951 - val_sparse_categorical_accuracy: 0.9344\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 1s 885us/step - loss: 0.1539 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.2505 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 1s 913us/step - loss: 0.1423 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2560 - val_sparse_categorical_accuracy: 0.9625\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 1s 880us/step - loss: 0.1428 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.2195 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 1s 908us/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.1294 - val_sparse_categorical_accuracy: 0.9698\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 1s 899us/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.1173 - val_sparse_categorical_accuracy: 0.9802\n",
      "Epoch 10/10\n",
      "934/937 [============================>.] - ETA: 0s - loss: 0.1345 - sparse_categorical_accuracy: 0.9622WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\n",
      "937/937 [==============================] - 1s 921us/step - loss: 0.1343 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.2662 - val_sparse_categorical_accuracy: 0.9427\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f86676ea890>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "model.fit(data_gen, steps_per_epoch=mnist_train_labels.shape[0]//64, epochs=10, validation_data=test_gen, validation_steps=mnist_test_labels.shape[0]//64//10)\n",
    "# we used to need fit_generator, but now the same functionality is incorporated into fit\n",
    "# note y doens't need to be specified when you use a generator or dataset object\n",
    "# validation split cannot be used either (you need a validation generator or array)\n",
    "# steps_per_epoch is the number of samples to read to finish 1 epoch (all training data)\n",
    "# if not specified, it will exhaust the input iterable and then count 1 epoch\n",
    "# batch_size is not specified because the data_gen already generate inputs in batches\n",
    "# validation_steps controls how many steps of the validation generator we run \n",
    "# (if not specified, it exhaust it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = val_generator(mnist_test_data,mnist_test_labels,batch_size=64)\n",
    "# you don't have to specify steps if the generator can be exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "156/156 [==============================] - 0s 654us/step - loss: 0.2472 - sparse_categorical_accuracy: 0.9423\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.2471640408039093, 0.942307710647583]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = val_generator(mnist_test_data,mnist_test_labels,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.clone_model(model)\n",
    "model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training loss and acc on epoch: 0 is 15.025984675456316 0.7232572115384616\n",
      "validation loss and acc is 4.842421054840088 0.8237000107765198\n",
      "training loss and acc on epoch: 1 is 3.2034847186161923 0.8020833333333334\n",
      "validation loss and acc is 1.7365195751190186 0.7680000066757202\n",
      "training loss and acc on epoch: 2 is 1.279325463068791 0.7399839743589743\n",
      "validation loss and acc is 1.054390788078308 0.7738999724388123\n",
      "training loss and acc on epoch: 3 is 1.0081953029984083 0.7759415064102564\n",
      "validation loss and acc is 0.9077612161636353 0.7901999950408936\n",
      "training loss and acc on epoch: 4 is 0.8830241513175842 0.7858573717948718\n",
      "validation loss and acc is 0.8889638781547546 0.795799970626831\n",
      "training loss and acc on epoch: 5 is 0.8020729174216589 0.8060897435897436\n",
      "validation loss and acc is 0.7860884666442871 0.8228999972343445\n",
      "training loss and acc on epoch: 6 is 0.6296593815279312 0.8277243589743589\n",
      "validation loss and acc is 0.733862042427063 0.8233000040054321\n",
      "training loss and acc on epoch: 7 is 0.6448085388311973 0.8365384615384616\n",
      "validation loss and acc is 0.7096157670021057 0.8240000009536743\n",
      "training loss and acc on epoch: 8 is 0.6337609613935152 0.8414463141025641\n",
      "validation loss and acc is 0.6651977300643921 0.8587999939918518\n",
      "training loss and acc on epoch: 9 is 0.5580103060182853 0.8596754807692307\n",
      "validation loss and acc is 0.6321167349815369 0.8598999977111816\n"
     ]
    }
   ],
   "source": [
    "numStep = mnist_test_labels.shape[0]//64\n",
    "for epoch in range(10): \n",
    "    loss_sum,acc_sum = 0,0\n",
    "    for step in range(numStep):\n",
    "        train_x, train_y = next(data_gen)\n",
    "        loss, acc = model2.train_on_batch(train_x,train_y)\n",
    "        loss_sum+=loss\n",
    "        acc_sum+=acc\n",
    "    val_loss, val_acc = model2.test_on_batch(mnist_test_data, mnist_test_labels)\n",
    "    print('training loss and acc on epoch:',epoch, 'is', loss_sum/numStep, acc_sum/numStep)\n",
    "    print('validation loss and acc is',val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# ImageDataGenerator is a class for quickly creating a generator object for images with \n",
    "# certain built-in preprocessing options.\n",
    "# Remember that when we use generators, all preprocessing must be done on the fly\n",
    "(cifar10_train_data, cifar10_train_label), (cifar10_test_data, cifar10_test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_process(data):\n",
    "    return np.repeat(np.mean(data, axis=-1)[...,np.newaxis],3,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGen = ImageDataGenerator(fill_mode='nearest',featurewise_center=True, featurewise_std_normalization=True, width_shift_range=0.3, height_shift_range=0.3, rotation_range=180, horizontal_flip=True, preprocessing_function=custom_process)\n",
    "# fill_mode='nearest' means when some pixels are emptied due to transformation, \n",
    "# they will be filled with the value of teh closest pixel. \n",
    "# There're other choices as well: constant, reflect, wrap.\n",
    "# featurewise_center centers all features at 0 (by subtracting feature-wise mean), \n",
    "# it needs precomputed mean.\n",
    "# featurewise_std_normalization normalizes the feature. It needs a precomputed std \n",
    "# All these precomputation are done when we call imgGen.fit\n",
    "# width_shift_range gives the percentage of max width that it randomly shifts on the fly\n",
    "# rotation_range gives the max angle it can rotate from the current original (same in both dir)\n",
    "# horizontal_flip is intuitive\n",
    "# preprocessing_function takes any function that reads in the input of 1 sample and output \n",
    "# a processed sample image. It should not change the image's dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGen.fit(cifar10_train_data)\n",
    "# this precomputes the mean and std in rolling fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = imgGen.flow(cifar10_train_data,cifar10_train_label,batch_size=64)\n",
    "# flow method outputs the actual generator object/function.\n",
    "# train_gen.n gives the total number of samples, so surely steps = train_gen.n//train_gen.batch_size \n",
    "# (it's an infinite generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could also use imgGen.flow_from_directory: there must be a parent directory and\n",
    "# a bunch of subdirectories whereby the name of each subdirectory indicate the class\n",
    "# that images in this subdirectory belong.\n",
    "# we can specify target_size (height, width); \n",
    "# color_mode = 'grayscale'/'rgb'/'rgba' indicating the color mode of the output images.\n",
    "# we can use classes to specify the list of subdirectory names and their class names.\n",
    "# Alternatively, it infers the class names based on subdirectory names directly.\n",
    "# the mapping between class name and index is in class_index\n",
    "# class_mode indicate output label modes (categorical/sparse/binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "# similar to images, we have a time-series generator to generate batches of time-series data\n",
    "# a time series data has two components: a data and a target\n",
    "# the data is a sequence of samples through time (with a certain length)\n",
    "# the target is what we want the model of this sequence of samples to map to\n",
    "# for time-series prediction (predicting next step), \n",
    "# this may well be the next sample in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset,TextLineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorSpec(shape=(), dtype=tf.int32, name=None)\n[(array([1, 2], dtype=int32), 1), (array([2, 3], dtype=int32), 2), (array([3, 4], dtype=int32), 3)]\nTensorSpec(shape=(3, 2), dtype=tf.int32, name=None)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = Dataset.from_tensor_slices([1,2,3])\n",
    "print(dataset1.element_spec)\n",
    "dataset2 = Dataset.from_tensor_slices(([[1,2],[2,3],[3,4]],[1,2,3]))\n",
    "print(list(dataset2.as_numpy_iterator()))\n",
    "dataset3 = Dataset.from_tensor_slices([((1,2),(2,3),(3,4)),((2,3),(2,3),(3,4))])\n",
    "print(dataset3.element_spec)\n",
    "# a tuple is interpreted very differently from a numpy or python list\n",
    "# both numpy array and python lists are interpreted as a tensor.\n",
    "# this method always slices the tensors in their first dimensions.\n",
    "# if we put in a tuple of tensors, it slices each independently \n",
    "# and then zip them together in batches of tuples of tensors.\n",
    "# The tensors provided must have equal number of first dimensions (the number of samples).\n",
    "# In each tensor we slice (they are sliced independently), each element should have same shape.\n",
    "# A dictoinary is interpreted similar to a tuple: it will slice each dictionary item separately\n",
    "# and generate a dataset of dictionary of elements \n",
    "# (the resulting dataset elements is accessed via dictionary keys, not indices). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.int32, name=None), (TensorSpec(shape=(2,), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None)))\n"
     ]
    }
   ],
   "source": [
    "# instead of slicing a tuple of tensors, we can also slice them separately and then zip them in a tuple.\n",
    "zippedData = Dataset.zip((dataset1,dataset2))\n",
    "print(zippedData.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[b'hello world',\n",
       " b'how are you',\n",
       " b'bingo juice',\n",
       " b'illegal aliens',\n",
       " b'build the wall',\n",
       " b'build the dome']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dataFromTextFile = TextLineDataset(['textFiles/text1.txt','textFiles/text2.txt','textFiles/text3.txt'])\n",
    "# it simply goes into each file and read each line as a separate sample where the element is the string.\n",
    "list(dataFromTextFile.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorSpec(shape=(), dtype=tf.string, name=None)\n[b'hello world', b'bingo juice', b'build the wall', b'how are you', b'illegal aliens', b'build the dome']\n"
     ]
    }
   ],
   "source": [
    "filePath = Dataset.from_tensor_slices(['textFiles/text1.txt','textFiles/text2.txt','textFiles/text3.txt'])\n",
    "interleaved = filePath.interleave(lambda x : TextLineDataset(x),cycle_length=3)\n",
    "# instead of processing each textfile sequentially if we just pass in a list of file paths to\n",
    "# TextLineDataset, interleave processes concurrently.\n",
    "# basically, interleave iterates over the samples of the dataset on which it's called. \n",
    "# then for each sample it calls the mappint function we provided and then proceed to the next.\n",
    "# After cycle_length of samples are finished, it returns to the first one \n",
    "# (and in each iteration it goes through cycle_length number of samples)\n",
    "print(interleaved.element_spec)\n",
    "print(list(interleaved.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([1, 2, 3], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "dataset4 = Dataset.from_tensors([1,2,3])\n",
    "print(list(dataset4.as_numpy_iterator()))\n",
    "# from_tensors always treats whatever passed in as a single sample (it doesn't slice it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.clone_model(model2)\n",
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))\n"
     ]
    }
   ],
   "source": [
    "mnist_train_dataset = Dataset.from_tensor_slices((mnist_train_data.astype('float32'),mnist_train_labels))\n",
    "print(mnist_train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_categorical(image, label):\n",
    "    return image/255.0, [(1 if i == label else 0) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = mnist_train_dataset.filter(lambda image, label : label<5) \n",
    "# filter takes in a function which maps the dataset sample to true or false\n",
    "# true: it will stay, false: it will be filtered out.\n",
    "mnist_train_dataset = mnist_train_dataset.map(map_to_categorical)\n",
    "# map function takes in an element/sample and spit out one (all tensors).\n",
    "# so naturally, any eager operation on numpy is not gonna work \n",
    "# (we can't convert to numpy because it's not eagerly executed). \n",
    "# That is why we are not using utils.to_categorical above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_val_dataset = mnist_train_dataset.skip(int(mnist_train_data.shape[0]*0.8*0.5))\n",
    "mnist_train_dataset = mnist_train_dataset.take(int(mnist_train_data.shape[0]*0.8*0.5))\n",
    "# keep in mind that dataset object is like a generator, \n",
    "# all the processing we define are not necessarily executed until it's actually called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None))\n(TensorSpec(shape=(64, 28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(64, 10), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "mnist_val_dataset = mnist_val_dataset.batch(64)\n",
    "print(mnist_val_dataset.element_spec)\n",
    "# if we don't drop_remainder the batch_size is not clearly defined, so it prints None\n",
    "mnist_train_dataset = mnist_train_dataset.batch(64, drop_remainder=True)\n",
    "# when drop_remainder is enabled, the remainders are dropped right here (you can't find it anymore)\n",
    "print(mnist_train_dataset.element_spec)\n",
    "mnist_train_dataset = mnist_train_dataset.shuffle(200)\n",
    "# what it means is that in choosing each batch of 128, \n",
    "# it chooses it from a shuffled buffer of 1000 data samples.\n",
    "# Again, shuffling occurs on the fly; we don't actually shuffle things here (reduce memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 4.9973e-05 - categorical_accuracy: 1.0000 - val_loss: 4.1405e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 4.3638e-05 - categorical_accuracy: 1.0000 - val_loss: 4.3216e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 3.8480e-05 - categorical_accuracy: 1.0000 - val_loss: 3.7554e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 3.3899e-05 - categorical_accuracy: 1.0000 - val_loss: 4.2900e-05 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 3.1056e-05 - categorical_accuracy: 1.0000 - val_loss: 3.9417e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe617918a90>"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "model3.fit(mnist_train_dataset,validation_data=mnist_val_dataset, epochs=5)\n",
    "# if the shuffle buffer size is too large, there may be some overhead. \n",
    "# instead of specifying a epochs, we could also do mnist_train_dataset.repeat(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = mnist_train_dataset.repeat(5)\n",
    "# if the number of times it repeats is not specified, it repeats indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.1653e-05 - categorical_accuracy: 1.0000 - val_loss: 4.0012e-05 - val_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe63315eb90>"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "model3.fit(mnist_train_dataset, validation_data=mnist_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.05 url/s]\n",
      "Dl Size...:   0%|          | 0/19 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.05 url/s]\n",
      "Dl Size...:   0%|          | 0/19 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|          | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.05 url/s]\n",
      "Dl Size...:   0%|          | 0/19 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.42 url/s]\n",
      "Dl Size...:   0%|          | 0/19 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.42 url/s]\n",
      "Dl Size...:   0%|          | 0/19 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  50%|█████     | 1/2 [00:01<00:00,  1.01 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.42 url/s]\n",
      "Dl Size...:   0%|          | 0/19 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:01<00:00,  1.38 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:03<00:01,  1.42 url/s]\n",
      "Dl Size...:   5%|▌         | 1/19 [00:03<01:05,  3.61s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:03<00:00,  1.38 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:04<00:01,  1.42 url/s]\n",
      "Dl Size...:  11%|█         | 2/19 [00:04<00:49,  2.88s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:04<00:00,  1.38 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:05<00:01,  1.42 url/s]\n",
      "Dl Size...:  16%|█▌        | 3/19 [00:05<00:36,  2.31s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:05<00:00,  1.38 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:08<00:01,  1.42 url/s]\n",
      "Dl Size...:  21%|██        | 4/19 [00:08<00:37,  2.47s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:08<00:00,  1.38 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:08<00:01,  1.42 url/s]\n",
      "Dl Size...:  26%|██▋       | 5/19 [00:08<00:25,  1.80s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:11<00:03,  3.75s/ url]\n",
      "Dl Size...:  26%|██▋       | 5/19 [00:11<00:25,  1.80s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:11<00:03,  3.75s/ url]\n",
      "Dl Size...:  26%|██▋       | 5/19 [00:11<00:25,  1.80s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:11<00:00,  1.38 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:12<00:03,  3.75s/ url]\n",
      "Dl Size...:  26%|██▋       | 5/19 [00:12<00:25,  1.80s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:12<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:12<00:03,  3.75s/ url]\n",
      "Dl Size...:  32%|███▏      | 6/19 [00:12<00:31,  2.45s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:12<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:16<00:03,  3.75s/ url]\n",
      "Dl Size...:  37%|███▋      | 7/19 [00:16<00:33,  2.80s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:16<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:19<00:03,  3.75s/ url]\n",
      "Dl Size...:  42%|████▏     | 8/19 [00:19<00:31,  2.83s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:19<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:21<00:03,  3.75s/ url]\n",
      "Dl Size...:  47%|████▋     | 9/19 [00:21<00:25,  2.50s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:21<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:22<00:03,  3.75s/ url]\n",
      "Dl Size...:  53%|█████▎    | 10/19 [00:22<00:18,  2.09s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:22<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:23<00:03,  3.75s/ url]\n",
      "Dl Size...:  58%|█████▊    | 11/19 [00:23<00:14,  1.80s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:23<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:24<00:03,  3.75s/ url]\n",
      "Dl Size...:  63%|██████▎   | 12/19 [00:24<00:11,  1.69s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:24<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:26<00:03,  3.75s/ url]\n",
      "Dl Size...:  68%|██████▊   | 13/19 [00:26<00:09,  1.61s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:26<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:28<00:03,  3.75s/ url]\n",
      "Dl Size...:  74%|███████▎  | 14/19 [00:28<00:08,  1.68s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:28<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:30<00:03,  3.75s/ url]\n",
      "Dl Size...:  79%|███████▉  | 15/19 [00:30<00:07,  1.82s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:30<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:32<00:03,  3.75s/ url]\n",
      "Dl Size...:  84%|████████▍ | 16/19 [00:32<00:05,  1.93s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:32<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:35<00:03,  3.75s/ url]\n",
      "Dl Size...:  89%|████████▉ | 17/19 [00:35<00:04,  2.19s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:35<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:38<00:03,  3.75s/ url]\n",
      "Dl Size...:  95%|█████████▍| 18/19 [00:38<00:02,  2.50s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:38<00:00,  3.79s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:41<00:03,  3.75s/ url]\n",
      "Dl Size...: 100%|██████████| 19/19 [00:41<00:00,  2.74s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:42<00:00, 11.88s/ url]\n",
      "Dl Size...: 100%|██████████| 19/19 [00:42<00:00,  2.74s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:42<00:00, 11.88s/ url]\n",
      "Dl Size...: 100%|██████████| 19/19 [00:42<00:00,  2.74s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|███████▌  | 3/4 [00:42<00:03,  3.79s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:43<00:00, 11.88s/ url]\n",
      "Dl Size...: 100%|██████████| 19/19 [00:43<00:00,  2.74s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:43<00:00, 10.82s/ file]\n",
      "Dl Size...: 100%|██████████| 19/19 [00:43<00:00,  2.28s/ MiB]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:43<00:00, 10.82s/ url]\n",
      "  0%|          | 0/2 [00:00<?, ? splits/s]\n",
      "  0%|          | 0/60000 [00:00<?, ? examples/s]\u001b[A\n",
      "  0%|          | 1/60000 [00:00<2:09:03,  7.75 examples/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 340/60000 [00:00<1:29:55, 11.06 examples/s]\u001b[A\n",
      "  1%|          | 679/60000 [00:00<1:02:40, 15.77 examples/s]\u001b[A\n",
      "  2%|▏         | 1042/60000 [00:00<43:41, 22.49 examples/s] \u001b[A\n",
      "  2%|▏         | 1406/60000 [00:00<30:28, 32.05 examples/s]\u001b[A\n",
      "  3%|▎         | 1767/60000 [00:00<21:16, 45.61 examples/s]\u001b[A\n",
      "  4%|▎         | 2125/60000 [00:00<14:53, 64.80 examples/s]\u001b[A\n",
      "  4%|▍         | 2486/60000 [00:00<10:26, 91.87 examples/s]\u001b[A\n",
      "  5%|▍         | 2848/60000 [00:00<07:20, 129.82 examples/s]\u001b[A\n",
      "  5%|▌         | 3207/60000 [00:01<05:10, 182.63 examples/s]\u001b[A\n",
      "  6%|▌         | 3563/60000 [00:01<03:41, 255.28 examples/s]\u001b[A\n",
      "  7%|▋         | 3912/60000 [00:01<02:38, 353.58 examples/s]\u001b[A\n",
      "  7%|▋         | 4261/60000 [00:01<01:55, 483.88 examples/s]\u001b[A\n",
      "  8%|▊         | 4611/60000 [00:01<01:24, 652.58 examples/s]\u001b[A\n",
      "  8%|▊         | 4960/60000 [00:01<01:03, 863.01 examples/s]\u001b[A\n",
      "  9%|▉         | 5315/60000 [00:01<00:48, 1116.35 examples/s]\u001b[A\n",
      "  9%|▉         | 5672/60000 [00:01<00:38, 1406.08 examples/s]\u001b[A\n",
      " 10%|█         | 6032/60000 [00:01<00:31, 1720.23 examples/s]\u001b[A\n",
      " 11%|█         | 6391/60000 [00:01<00:26, 2038.36 examples/s]\u001b[A\n",
      " 11%|█▏        | 6756/60000 [00:02<00:22, 2349.18 examples/s]\u001b[A\n",
      " 12%|█▏        | 7115/60000 [00:02<00:20, 2617.40 examples/s]\u001b[A\n",
      " 12%|█▏        | 7476/60000 [00:02<00:18, 2852.13 examples/s]\u001b[A\n",
      " 13%|█▎        | 7835/60000 [00:02<00:17, 3015.34 examples/s]\u001b[A\n",
      " 14%|█▎        | 8197/60000 [00:02<00:16, 3173.85 examples/s]\u001b[A\n",
      " 14%|█▍        | 8562/60000 [00:02<00:15, 3302.70 examples/s]\u001b[A\n",
      " 15%|█▍        | 8922/60000 [00:02<00:15, 3306.44 examples/s]\u001b[A\n",
      " 15%|█▌        | 9281/60000 [00:02<00:14, 3386.10 examples/s]\u001b[A\n",
      " 16%|█▌        | 9635/60000 [00:02<00:15, 3349.32 examples/s]\u001b[A\n",
      " 17%|█▋        | 9997/60000 [00:02<00:14, 3425.15 examples/s]\u001b[A\n",
      " 17%|█▋        | 10358/60000 [00:03<00:14, 3476.85 examples/s]\u001b[A\n",
      " 18%|█▊        | 10714/60000 [00:03<00:14, 3498.59 examples/s]\u001b[A\n",
      " 18%|█▊        | 11071/60000 [00:03<00:13, 3517.73 examples/s]\u001b[A\n",
      " 19%|█▉        | 11426/60000 [00:03<00:14, 3451.10 examples/s]\u001b[A\n",
      " 20%|█▉        | 11783/60000 [00:03<00:13, 3485.37 examples/s]\u001b[A\n",
      " 20%|██        | 12145/60000 [00:03<00:13, 3522.35 examples/s]\u001b[A\n",
      " 21%|██        | 12504/60000 [00:03<00:13, 3541.33 examples/s]\u001b[A\n",
      " 21%|██▏       | 12862/60000 [00:03<00:13, 3551.81 examples/s]\u001b[A\n",
      " 22%|██▏       | 13218/60000 [00:03<00:14, 3273.88 examples/s]\u001b[A\n",
      " 23%|██▎       | 13551/60000 [00:03<00:14, 3233.86 examples/s]\u001b[A\n",
      " 23%|██▎       | 13910/60000 [00:04<00:13, 3332.96 examples/s]\u001b[A\n",
      " 24%|██▍       | 14272/60000 [00:04<00:13, 3412.85 examples/s]\u001b[A\n",
      " 24%|██▍       | 14616/60000 [00:04<00:13, 3396.44 examples/s]\u001b[A\n",
      " 25%|██▍       | 14973/60000 [00:04<00:13, 3444.99 examples/s]\u001b[A\n",
      " 26%|██▌       | 15337/60000 [00:04<00:12, 3500.83 examples/s]\u001b[A\n",
      " 26%|██▌       | 15696/60000 [00:04<00:12, 3526.02 examples/s]\u001b[A\n",
      " 27%|██▋       | 16053/60000 [00:04<00:12, 3537.29 examples/s]\u001b[A\n",
      " 27%|██▋       | 16408/60000 [00:04<00:12, 3536.04 examples/s]\u001b[A\n",
      " 28%|██▊       | 16778/60000 [00:04<00:12, 3581.60 examples/s]\u001b[A\n",
      " 29%|██▊       | 17137/60000 [00:05<00:11, 3578.34 examples/s]\u001b[A\n",
      " 29%|██▉       | 17496/60000 [00:05<00:11, 3576.78 examples/s]\u001b[A\n",
      " 30%|██▉       | 17854/60000 [00:05<00:11, 3574.14 examples/s]\u001b[A\n",
      " 30%|███       | 18212/60000 [00:05<00:11, 3520.87 examples/s]\u001b[A\n",
      " 31%|███       | 18565/60000 [00:05<00:11, 3514.59 examples/s]\u001b[A\n",
      " 32%|███▏      | 18917/60000 [00:05<00:11, 3500.31 examples/s]\u001b[A\n",
      " 32%|███▏      | 19269/60000 [00:05<00:11, 3505.85 examples/s]\u001b[A\n",
      " 33%|███▎      | 19631/60000 [00:05<00:11, 3539.21 examples/s]\u001b[A\n",
      " 33%|███▎      | 19986/60000 [00:05<00:11, 3517.67 examples/s]\u001b[A\n",
      " 34%|███▍      | 20348/60000 [00:05<00:11, 3545.44 examples/s]\u001b[A\n",
      " 35%|███▍      | 20703/60000 [00:06<00:11, 3451.49 examples/s]\u001b[A\n",
      " 35%|███▌      | 21056/60000 [00:06<00:11, 3470.61 examples/s]\u001b[A\n",
      " 36%|███▌      | 21411/60000 [00:06<00:11, 3490.93 examples/s]\u001b[A\n",
      " 36%|███▋      | 21761/60000 [00:06<00:11, 3466.70 examples/s]\u001b[A\n",
      " 37%|███▋      | 22122/60000 [00:06<00:10, 3507.33 examples/s]\u001b[A\n",
      " 37%|███▋      | 22480/60000 [00:06<00:10, 3526.61 examples/s]\u001b[A\n",
      " 38%|███▊      | 22841/60000 [00:06<00:10, 3550.67 examples/s]\u001b[A\n",
      " 39%|███▊      | 23197/60000 [00:06<00:10, 3535.81 examples/s]\u001b[A\n",
      " 39%|███▉      | 23555/60000 [00:06<00:10, 3547.04 examples/s]\u001b[A\n",
      " 40%|███▉      | 23915/60000 [00:06<00:10, 3562.29 examples/s]\u001b[A\n",
      " 40%|████      | 24273/60000 [00:07<00:10, 3565.40 examples/s]\u001b[A\n",
      " 41%|████      | 24635/60000 [00:07<00:09, 3581.09 examples/s]\u001b[A\n",
      " 42%|████▏     | 24994/60000 [00:07<00:09, 3569.39 examples/s]\u001b[A\n",
      " 42%|████▏     | 25351/60000 [00:07<00:09, 3507.03 examples/s]\u001b[A\n",
      " 43%|████▎     | 25702/60000 [00:07<00:10, 3415.15 examples/s]\u001b[A\n",
      " 43%|████▎     | 26069/60000 [00:07<00:09, 3486.06 examples/s]\u001b[A\n",
      " 44%|████▍     | 26424/60000 [00:07<00:09, 3503.00 examples/s]\u001b[A\n",
      " 45%|████▍     | 26783/60000 [00:07<00:09, 3527.83 examples/s]\u001b[A\n",
      " 45%|████▌     | 27142/60000 [00:07<00:09, 3544.84 examples/s]\u001b[A\n",
      " 46%|████▌     | 27497/60000 [00:07<00:09, 3546.07 examples/s]\u001b[A\n",
      " 46%|████▋     | 27855/60000 [00:08<00:09, 3553.80 examples/s]\u001b[A\n",
      " 47%|████▋     | 28215/60000 [00:08<00:08, 3565.56 examples/s]\u001b[A\n",
      " 48%|████▊     | 28574/60000 [00:08<00:08, 3571.75 examples/s]\u001b[A\n",
      " 48%|████▊     | 28932/60000 [00:08<00:08, 3518.34 examples/s]\u001b[A\n",
      " 49%|████▉     | 29285/60000 [00:08<00:08, 3442.48 examples/s]\u001b[A\n",
      " 49%|████▉     | 29630/60000 [00:08<00:09, 3368.14 examples/s]\u001b[A\n",
      " 50%|████▉     | 29969/60000 [00:08<00:08, 3374.35 examples/s]\u001b[A\n",
      " 51%|█████     | 30313/60000 [00:08<00:08, 3392.92 examples/s]\u001b[A\n",
      " 51%|█████     | 30678/60000 [00:08<00:08, 3465.30 examples/s]\u001b[A\n",
      " 52%|█████▏    | 31044/60000 [00:08<00:08, 3520.53 examples/s]\u001b[A\n",
      " 52%|█████▏    | 31416/60000 [00:09<00:07, 3576.24 examples/s]\u001b[A\n",
      " 53%|█████▎    | 31786/60000 [00:09<00:07, 3611.83 examples/s]\u001b[A\n",
      " 54%|█████▎    | 32148/60000 [00:09<00:07, 3611.62 examples/s]\u001b[A\n",
      " 54%|█████▍    | 32510/60000 [00:09<00:07, 3594.42 examples/s]\u001b[A\n",
      " 55%|█████▍    | 32873/60000 [00:09<00:07, 3603.38 examples/s]\u001b[A\n",
      " 55%|█████▌    | 33240/60000 [00:09<00:07, 3621.89 examples/s]\u001b[A\n",
      " 56%|█████▌    | 33605/60000 [00:09<00:07, 3628.55 examples/s]\u001b[A\n",
      " 57%|█████▋    | 33974/60000 [00:09<00:07, 3644.23 examples/s]\u001b[A\n",
      " 57%|█████▋    | 34340/60000 [00:09<00:07, 3647.94 examples/s]\u001b[A\n",
      " 58%|█████▊    | 34707/60000 [00:09<00:06, 3652.29 examples/s]\u001b[A\n",
      " 58%|█████▊    | 35073/60000 [00:10<00:07, 3550.67 examples/s]\u001b[A\n",
      " 59%|█████▉    | 35429/60000 [00:10<00:07, 3340.44 examples/s]\u001b[A\n",
      " 60%|█████▉    | 35795/60000 [00:10<00:07, 3430.06 examples/s]\u001b[A\n",
      " 60%|██████    | 36152/60000 [00:10<00:06, 3470.76 examples/s]\u001b[A\n",
      " 61%|██████    | 36518/60000 [00:10<00:06, 3525.33 examples/s]\u001b[A\n",
      " 61%|██████▏   | 36886/60000 [00:10<00:06, 3567.87 examples/s]\u001b[A\n",
      " 62%|██████▏   | 37252/60000 [00:10<00:06, 3594.78 examples/s]\u001b[A\n",
      " 63%|██████▎   | 37614/60000 [00:10<00:06, 3601.28 examples/s]\u001b[A\n",
      " 63%|██████▎   | 37986/60000 [00:10<00:06, 3634.31 examples/s]\u001b[A\n",
      " 64%|██████▍   | 38352/60000 [00:11<00:05, 3641.43 examples/s]\u001b[A\n",
      " 65%|██████▍   | 38721/60000 [00:11<00:05, 3655.72 examples/s]\u001b[A\n",
      " 65%|██████▌   | 39087/60000 [00:11<00:05, 3651.37 examples/s]\u001b[A\n",
      " 66%|██████▌   | 39453/60000 [00:11<00:05, 3649.76 examples/s]\u001b[A\n",
      " 66%|██████▋   | 39819/60000 [00:11<00:05, 3628.34 examples/s]\u001b[A\n",
      " 67%|██████▋   | 40183/60000 [00:11<00:05, 3629.20 examples/s]\u001b[A\n",
      " 68%|██████▊   | 40551/60000 [00:11<00:05, 3641.26 examples/s]\u001b[A\n",
      " 68%|██████▊   | 40921/60000 [00:11<00:05, 3653.98 examples/s]\u001b[A\n",
      " 69%|██████▉   | 41287/60000 [00:11<00:05, 3642.01 examples/s]\u001b[A\n",
      " 69%|██████▉   | 41657/60000 [00:11<00:05, 3657.60 examples/s]\u001b[A\n",
      " 70%|███████   | 42029/60000 [00:12<00:04, 3673.52 examples/s]\u001b[A\n",
      " 71%|███████   | 42397/60000 [00:12<00:04, 3661.83 examples/s]\u001b[A\n",
      " 71%|███████▏  | 42764/60000 [00:12<00:04, 3660.37 examples/s]\u001b[A\n",
      " 72%|███████▏  | 43131/60000 [00:12<00:04, 3616.96 examples/s]\u001b[A\n",
      " 73%|███████▎  | 43502/60000 [00:12<00:04, 3641.93 examples/s]\u001b[A\n",
      " 73%|███████▎  | 43870/60000 [00:12<00:04, 3653.16 examples/s]\u001b[A\n",
      " 74%|███████▎  | 44240/60000 [00:12<00:04, 3666.63 examples/s]\u001b[A\n",
      " 74%|███████▍  | 44607/60000 [00:12<00:04, 3652.63 examples/s]\u001b[A\n",
      " 75%|███████▍  | 44973/60000 [00:12<00:04, 3646.95 examples/s]\u001b[A\n",
      " 76%|███████▌  | 45345/60000 [00:12<00:03, 3667.69 examples/s]\u001b[A\n",
      " 76%|███████▌  | 45712/60000 [00:13<00:03, 3638.24 examples/s]\u001b[A\n",
      " 77%|███████▋  | 46078/60000 [00:13<00:03, 3644.48 examples/s]\u001b[A\n",
      " 77%|███████▋  | 46446/60000 [00:13<00:03, 3654.42 examples/s]\u001b[A\n",
      " 78%|███████▊  | 46812/60000 [00:13<00:03, 3644.63 examples/s]\u001b[A\n",
      " 79%|███████▊  | 47177/60000 [00:13<00:03, 3641.02 examples/s]\u001b[A\n",
      " 79%|███████▉  | 47552/60000 [00:13<00:03, 3671.02 examples/s]\u001b[A\n",
      " 80%|███████▉  | 47920/60000 [00:13<00:03, 3659.63 examples/s]\u001b[A\n",
      " 80%|████████  | 48287/60000 [00:13<00:03, 3648.66 examples/s]\u001b[A\n",
      " 81%|████████  | 48655/60000 [00:13<00:03, 3655.04 examples/s]\u001b[A\n",
      " 82%|████████▏ | 49028/60000 [00:13<00:02, 3677.19 examples/s]\u001b[A\n",
      " 82%|████████▏ | 49396/60000 [00:14<00:02, 3656.37 examples/s]\u001b[A\n",
      " 83%|████████▎ | 49764/60000 [00:14<00:02, 3662.49 examples/s]\u001b[A\n",
      " 84%|████████▎ | 50131/60000 [00:14<00:02, 3647.30 examples/s]\u001b[A\n",
      " 84%|████████▍ | 50496/60000 [00:14<00:02, 3615.63 examples/s]\u001b[A\n",
      " 85%|████████▍ | 50860/60000 [00:14<00:02, 3622.25 examples/s]\u001b[A\n",
      " 85%|████████▌ | 51227/60000 [00:14<00:02, 3635.41 examples/s]\u001b[A\n",
      " 86%|████████▌ | 51593/60000 [00:14<00:02, 3642.53 examples/s]\u001b[A\n",
      " 87%|████████▋ | 51958/60000 [00:14<00:02, 3606.53 examples/s]\u001b[A\n",
      " 87%|████████▋ | 52319/60000 [00:14<00:02, 3600.74 examples/s]\u001b[A\n",
      " 88%|████████▊ | 52689/60000 [00:14<00:02, 3628.02 examples/s]\u001b[A\n",
      " 88%|████████▊ | 53052/60000 [00:15<00:01, 3571.27 examples/s]\u001b[A\n",
      " 89%|████████▉ | 53417/60000 [00:15<00:01, 3593.64 examples/s]\u001b[A\n",
      " 90%|████████▉ | 53786/60000 [00:15<00:01, 3615.57 examples/s]\u001b[A\n",
      " 90%|█████████ | 54148/60000 [00:15<00:01, 3606.18 examples/s]\u001b[A\n",
      " 91%|█████████ | 54509/60000 [00:15<00:01, 3604.38 examples/s]\u001b[A\n",
      " 91%|█████████▏| 54880/60000 [00:15<00:01, 3633.77 examples/s]\u001b[A\n",
      " 92%|█████████▏| 55250/60000 [00:15<00:01, 3651.40 examples/s]\u001b[A\n",
      " 93%|█████████▎| 55616/60000 [00:15<00:01, 3615.55 examples/s]\u001b[A\n",
      " 93%|█████████▎| 55984/60000 [00:15<00:01, 3633.92 examples/s]\u001b[A\n",
      " 94%|█████████▍| 56350/60000 [00:15<00:01, 3639.66 examples/s]\u001b[A\n",
      " 95%|█████████▍| 56715/60000 [00:16<00:00, 3630.20 examples/s]\u001b[A\n",
      " 95%|█████████▌| 57082/60000 [00:16<00:00, 3640.88 examples/s]\u001b[A\n",
      " 96%|█████████▌| 57447/60000 [00:16<00:00, 3632.15 examples/s]\u001b[A\n",
      " 96%|█████████▋| 57811/60000 [00:16<00:00, 3605.27 examples/s]\u001b[A\n",
      " 97%|█████████▋| 58177/60000 [00:16<00:00, 3620.08 examples/s]\u001b[A\n",
      " 98%|█████████▊| 58552/60000 [00:16<00:00, 3656.91 examples/s]\u001b[A\n",
      " 98%|█████████▊| 58918/60000 [00:16<00:00, 3401.54 examples/s]\u001b[A\n",
      " 99%|█████████▉| 59262/60000 [00:16<00:00, 3334.96 examples/s]\u001b[A\n",
      " 99%|█████████▉| 59599/60000 [00:16<00:00, 3303.58 examples/s]\u001b[A\n",
      "100%|█████████▉| 59932/60000 [00:17<00:00, 3043.78 examples/s]\u001b[A\n",
      "                                                              \u001b[A\n",
      "  0%|          | 0/60000 [00:00<?, ? examples/s]\u001b[A\n",
      " 18%|█▊        | 10881/60000 [00:00<00:00, 108806.73 examples/s]\u001b[AShuffling and writing examples to /Users/michaelhyh/tensorflow_datasets/kmnist/3.0.1.incomplete46L4AF/kmnist-train.tfrecord\n",
      "\n",
      " 59%|█████▉    | 35573/60000 [00:00<00:00, 130746.23 examples/s]\u001b[A\n",
      " 96%|█████████▌| 57507/60000 [00:00<00:00, 148772.69 examples/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:17<00:17, 17.41s/ splits]\n",
      "  0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "  2%|▏         | 247/10000 [00:00<00:03, 2469.53 examples/s]\u001b[A\n",
      "  6%|▌         | 573/10000 [00:00<00:03, 2662.67 examples/s]\u001b[A\n",
      "  9%|▉         | 903/10000 [00:00<00:03, 2824.42 examples/s]\u001b[A\n",
      " 12%|█▏        | 1206/10000 [00:00<00:03, 2881.07 examples/s]\u001b[A\n",
      " 15%|█▍        | 1490/10000 [00:00<00:02, 2867.34 examples/s]\u001b[A\n",
      " 18%|█▊        | 1809/10000 [00:00<00:02, 2955.73 examples/s]\u001b[A\n",
      " 21%|██▏       | 2130/10000 [00:00<00:02, 3025.75 examples/s]\u001b[A\n",
      " 25%|██▍       | 2453/10000 [00:00<00:02, 3082.43 examples/s]\u001b[A\n",
      " 28%|██▊       | 2772/10000 [00:00<00:02, 3112.22 examples/s]\u001b[A\n",
      " 31%|███       | 3093/10000 [00:01<00:02, 3139.85 examples/s]\u001b[A\n",
      " 34%|███▍      | 3434/10000 [00:01<00:02, 3215.40 examples/s]\u001b[A\n",
      " 38%|███▊      | 3784/10000 [00:01<00:01, 3294.21 examples/s]\u001b[A\n",
      " 41%|████      | 4124/10000 [00:01<00:01, 3323.85 examples/s]\u001b[A\n",
      " 45%|████▍     | 4455/10000 [00:01<00:01, 3296.81 examples/s]\u001b[A\n",
      " 48%|████▊     | 4784/10000 [00:01<00:01, 3279.86 examples/s]\u001b[A\n",
      " 51%|█████     | 5119/10000 [00:01<00:01, 3300.45 examples/s]\u001b[A\n",
      " 55%|█████▍    | 5478/10000 [00:01<00:01, 3380.43 examples/s]\u001b[A\n",
      " 58%|█████▊    | 5817/10000 [00:01<00:01, 3377.89 examples/s]\u001b[A\n",
      " 62%|██████▏   | 6165/10000 [00:01<00:01, 3405.96 examples/s]\u001b[A\n",
      " 65%|██████▌   | 6522/10000 [00:02<00:01, 3453.30 examples/s]\u001b[A\n",
      " 69%|██████▊   | 6872/10000 [00:02<00:00, 3467.08 examples/s]\u001b[A\n",
      " 72%|███████▏  | 7219/10000 [00:02<00:00, 3446.98 examples/s]\u001b[A\n",
      " 76%|███████▌  | 7564/10000 [00:02<00:00, 3378.32 examples/s]\u001b[A\n",
      " 79%|███████▉  | 7905/10000 [00:02<00:00, 3386.55 examples/s]\u001b[A\n",
      " 83%|████████▎ | 8251/10000 [00:02<00:00, 3407.65 examples/s]\u001b[A\n",
      " 86%|████████▌ | 8594/10000 [00:02<00:00, 3413.59 examples/s]\u001b[A\n",
      " 90%|████████▉ | 8954/10000 [00:02<00:00, 3466.70 examples/s]\u001b[A\n",
      " 93%|█████████▎| 9301/10000 [00:02<00:00, 3407.46 examples/s]\u001b[A\n",
      " 96%|█████████▋| 9643/10000 [00:02<00:00, 3325.50 examples/s]\u001b[A\n",
      "100%|█████████▉| 9977/10000 [00:03<00:00, 3324.80 examples/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "  0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling and writing examples to /Users/michaelhyh/tensorflow_datasets/kmnist/3.0.1.incomplete46L4AF/kmnist-test.tfrecord\n",
      "\u001b[1mDataset kmnist downloaded and prepared to /Users/michaelhyh/tensorflow_datasets/kmnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "kmnist_data = tfds.load('kmnist',split=None)\n",
    "# tfds.list_builders() lists all available datasets\n",
    "# split=None means the train and test data will be in separated in a dictionary\n",
    "# of course the method loads in tensorflow dataset directly\n",
    "kmnist_train_dataset = kmnist_data['train']\n",
    "kmnist_test_dataset = kmnist_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}